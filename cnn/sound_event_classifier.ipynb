{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8bMse_qgCnUQ",
    "outputId": "171fa933-d034-4fba-bb2a-fd5790e1efa7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.1-cp37-cp37m-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/park-yujin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "\u001b[K     |████████████████████████████████| 300 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/park-yujin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=dbdcab446f5bd76bfc4ef9daaa86801dd8b2eb0f40860ab3fb34df2e14dbc95c\n",
      "  Stored in directory: /Users/park-yujin/Library/Caches/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, threadpoolctl, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.16.0 scikit-learn-0.23.1 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.0.5-cp37-cp37m-macosx_10_9_x86_64.whl (10.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.0 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/park-yujin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages (from pandas) (1.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/park-yujin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/park-yujin/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.0.5 pytz-2020.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,TimeDistributed\n",
    "from keras.layers import Convolution2D, MaxPooling2D,MaxPooling1D,Conv1D\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "\n",
    "\n",
    "def reSample(data, samples):\n",
    "    r = len(data)/samples #re-sampling ratio\n",
    "    newdata = []\n",
    "    for i in range(0,samples):\n",
    "        newdata.append(data[int(i*r)])\n",
    "    return np.array(newdata)\n",
    "  \n",
    "  \n",
    "train_subjects = ['s07', 's16', 's09', 's13', 's04', 's11', 's15', 's01', 's12', 's10', 's06', 's08']\n",
    "validation_subjects = ['s02', 's03']\n",
    "test_subjects = ['s05', 's17']\n",
    "\n",
    "def get_data(path,sampleSize):\n",
    "    \n",
    "    mergedActivities = ['Drinking', 'Eating', 'LyingDown', 'OpeningPillContainer', \n",
    "                          'PickingObject', 'Reading', 'SitStill', 'Sitting', 'Sleeping', \n",
    "                          'StandUp', 'UseLaptop', 'UsingPhone', 'WakeUp', 'Walking', \n",
    "                          'WaterPouring', 'Writing']\n",
    "    \n",
    "    specificActivities = ['Calling', 'Clapping', 'Falling', 'Sweeping', 'WashingHand', 'WatchingTV']\n",
    "    \n",
    "    enteringExiting = ['Entering', 'Exiting']\n",
    "    \n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    X_validation = []\n",
    "    Y_validation = []\n",
    "    \n",
    "    ## Note that 'stft_257_1' contains the STFT features with specification specified in the medium article; \n",
    "    ## https://medium.com/@chathuranga.15/sound-event-classification-using-machine-learning-8768092beafc\n",
    "    \n",
    "    for file in os.listdir(path + 'stft_257_1/'):\n",
    "        if int(file.split(\"__\")[1].split(\"_\")[0])!=1:\n",
    "          a = (np.load(path + \"stft_257_1/\" + file)).T\n",
    "          label = file.split('_')[-1].split(\".\")[0]\n",
    "          if(label in specificActivities):\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "#                   X_train.append(reSample(a,sampleSize))\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          elif(label in enteringExiting):\n",
    "                label = \"enteringExiting\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  #samples[label].append(reSample(a,sampleSize))\n",
    "          else:\n",
    "                label = \"other\"\n",
    "              #if(a.shape[0]>100 and a.shape[0]<500):\n",
    "                if file.split(\"_\")[0] in train_subjects:\n",
    "                  X_train.append(np.mean(a,axis=0))\n",
    "                  Y_train.append(label)\n",
    "                elif file.split(\"_\")[0] in validation_subjects:\n",
    "                  X_validation.append(np.mean(a,axis=0))\n",
    "                  Y_validation.append(label)\n",
    "                else:\n",
    "                  X_test.append(np.mean(a,axis=0))\n",
    "                  Y_test.append(label)\n",
    "                  \n",
    "    X_train = np.array(X_train)\n",
    "    Y_train = np.array(Y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    Y_test = np.array(Y_test)\n",
    "    X_validation = np.array(X_validation)\n",
    "    Y_validation = np.array(Y_validation)\n",
    "    \n",
    "    return X_train,Y_train,X_validation,Y_validation,X_test,Y_test\n",
    "  \n",
    "def print_M(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                s += str(conf_M[i][j])\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print()\n",
    "        \n",
    "def print_M_P(conf_M):\n",
    "        s = \"activity,\"\n",
    "        for i in range(len(conf_M)):\n",
    "            s += lb.inverse_transform([i])[0] + \",\"\n",
    "        print(s[:-1])\n",
    "        for i in range(len(conf_M)):\n",
    "            s = \"\"\n",
    "            for j in range(len(conf_M)):\n",
    "                val = conf_M[i][j]/float(sum(conf_M[i]))\n",
    "                s += str(round(val,2))\n",
    "                s += \",\"\n",
    "            print(lb.inverse_transform([i])[0],\",\", s[:-1])\n",
    "        print()        \n",
    "        \n",
    "def showResult():\n",
    "  predictions = [np.argmax(y) for y in result]\n",
    "  expected = [np.argmax(y) for y in y_test]\n",
    "\n",
    "  conf_M = []\n",
    "  num_labels=y_test[0].shape[0]\n",
    "  for i in range(num_labels):\n",
    "      r = []\n",
    "      for j in range(num_labels):\n",
    "          r.append(0)\n",
    "      conf_M.append(r)\n",
    "\n",
    "  \n",
    "\n",
    "  n_tests = len(predictions)\n",
    "  for i in range(n_tests):        \n",
    "      conf_M[expected[i]][predictions[i]] += 1\n",
    "\n",
    "  print_M(conf_M)\n",
    "  print_M_P(conf_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJXscHVhEBYC"
   },
   "outputs": [],
   "source": [
    "featuresPath = \"STFT_features/\"\n",
    "\n",
    "a,b,c,d,e,f = get_data(featuresPath,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-wO90syxC5d8",
    "outputId": "4128b9f5-5f37-4226-8334-4505efafb8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: 880\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train,X_validation,Y_validation,X_test,Y_test = a,b,c,d,e,f\n",
    "\n",
    "n_samples = len(Y_train)\n",
    "print(\"No of training samples: \" + str(n_samples))\n",
    "order = np.array(range(n_samples))\n",
    "np.random.shuffle(order)\n",
    "X_train = X_train[order]\n",
    "Y_train = Y_train[order]\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(Y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(Y_test))\n",
    "y_validation = np_utils.to_categorical(lb.fit_transform(Y_validation))\n",
    "num_labels = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e7JS59xYDB06",
    "outputId": "5b249629-b357-4bb7-a463-cc37c7e78e83",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_labels = y_train.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# build model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(1025,))) #257\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 1.3638 - accuracy: 0.7239 - val_loss: 0.6480 - val_accuracy: 0.8082\n",
      "Epoch 2/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.7836 - accuracy: 0.7716 - val_loss: 0.5645 - val_accuracy: 0.8082\n",
      "Epoch 3/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.7006 - accuracy: 0.7898 - val_loss: 0.5520 - val_accuracy: 0.8151\n",
      "Epoch 4/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.7442 - accuracy: 0.7830 - val_loss: 0.6337 - val_accuracy: 0.8219\n",
      "Epoch 5/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.8034 - val_loss: 0.5211 - val_accuracy: 0.8151\n",
      "Epoch 6/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.8023 - val_loss: 0.4658 - val_accuracy: 0.8151\n",
      "Epoch 7/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.8114 - val_loss: 0.4310 - val_accuracy: 0.8562\n",
      "Epoch 8/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.8216 - val_loss: 0.3932 - val_accuracy: 0.8699\n",
      "Epoch 9/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.8307 - val_loss: 0.4142 - val_accuracy: 0.8699\n",
      "Epoch 10/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8420 - val_loss: 0.4273 - val_accuracy: 0.8493\n",
      "Epoch 11/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8489 - val_loss: 0.5085 - val_accuracy: 0.8356\n",
      "Epoch 12/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8636 - val_loss: 0.4405 - val_accuracy: 0.8904\n",
      "Epoch 13/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.8682 - val_loss: 0.3798 - val_accuracy: 0.8836\n",
      "Epoch 14/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8864 - val_loss: 0.3790 - val_accuracy: 0.8767\n",
      "Epoch 15/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8818 - val_loss: 0.4575 - val_accuracy: 0.8767\n",
      "Epoch 16/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8875 - val_loss: 0.4393 - val_accuracy: 0.8836\n",
      "Epoch 17/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8966 - val_loss: 0.4086 - val_accuracy: 0.8767\n",
      "Epoch 18/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.9125 - val_loss: 0.4417 - val_accuracy: 0.8699\n",
      "Epoch 19/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.9193 - val_loss: 0.5249 - val_accuracy: 0.8767\n",
      "Epoch 20/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9216 - val_loss: 0.3363 - val_accuracy: 0.8904\n",
      "Epoch 21/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9250 - val_loss: 0.4166 - val_accuracy: 0.8836\n",
      "Epoch 22/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9318 - val_loss: 0.4745 - val_accuracy: 0.8699\n",
      "Epoch 23/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.9284 - val_loss: 0.4983 - val_accuracy: 0.8904\n",
      "Epoch 24/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9386 - val_loss: 0.3854 - val_accuracy: 0.8973\n",
      "Epoch 25/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9489 - val_loss: 0.4670 - val_accuracy: 0.8904\n",
      "Epoch 26/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1707 - accuracy: 0.9455 - val_loss: 0.3380 - val_accuracy: 0.8973\n",
      "Epoch 27/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9557 - val_loss: 0.4208 - val_accuracy: 0.8699\n",
      "Epoch 28/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9318 - val_loss: 0.4860 - val_accuracy: 0.8904\n",
      "Epoch 29/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9625 - val_loss: 0.3730 - val_accuracy: 0.8767\n",
      "Epoch 30/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9625 - val_loss: 0.6928 - val_accuracy: 0.8767\n",
      "Epoch 31/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9580 - val_loss: 0.4899 - val_accuracy: 0.8767\n",
      "Epoch 32/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9739 - val_loss: 0.5507 - val_accuracy: 0.8836\n",
      "Epoch 33/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9750 - val_loss: 0.4969 - val_accuracy: 0.8836\n",
      "Epoch 34/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.7441 - val_accuracy: 0.8904\n",
      "Epoch 35/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9761 - val_loss: 0.6389 - val_accuracy: 0.8767\n",
      "Epoch 36/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.9682 - val_loss: 0.8221 - val_accuracy: 0.8356\n",
      "Epoch 37/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1652 - accuracy: 0.9511 - val_loss: 0.5051 - val_accuracy: 0.8904\n",
      "Epoch 38/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9648 - val_loss: 0.4324 - val_accuracy: 0.9178\n",
      "Epoch 39/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9534 - val_loss: 0.5270 - val_accuracy: 0.8767\n",
      "Epoch 40/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9432 - val_loss: 0.6075 - val_accuracy: 0.8973\n",
      "Epoch 41/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy: 0.9761 - val_loss: 0.6266 - val_accuracy: 0.8973\n",
      "Epoch 42/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9807 - val_loss: 0.6324 - val_accuracy: 0.8973\n",
      "Epoch 43/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 0.7243 - val_accuracy: 0.8973\n",
      "Epoch 44/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9807 - val_loss: 0.7424 - val_accuracy: 0.8699\n",
      "Epoch 45/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.9500 - val_loss: 0.6460 - val_accuracy: 0.8630\n",
      "Epoch 46/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9716 - val_loss: 0.6179 - val_accuracy: 0.8973\n",
      "Epoch 47/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9784 - val_loss: 0.7136 - val_accuracy: 0.8973\n",
      "Epoch 48/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9761 - val_loss: 0.6926 - val_accuracy: 0.8973\n",
      "Epoch 49/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9864 - val_loss: 0.8728 - val_accuracy: 0.8904\n",
      "Epoch 50/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0877 - accuracy: 0.9727 - val_loss: 0.4615 - val_accuracy: 0.8767\n",
      "Epoch 51/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9761 - val_loss: 0.7142 - val_accuracy: 0.8836\n",
      "Epoch 52/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9898 - val_loss: 0.8299 - val_accuracy: 0.8767\n",
      "Epoch 53/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9864 - val_loss: 0.7299 - val_accuracy: 0.8425\n",
      "Epoch 54/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9909 - val_loss: 0.7845 - val_accuracy: 0.8630\n",
      "Epoch 55/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.9061 - val_accuracy: 0.8836\n",
      "Epoch 56/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9807 - val_loss: 0.8139 - val_accuracy: 0.8767\n",
      "Epoch 57/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9932 - val_loss: 0.9138 - val_accuracy: 0.8699\n",
      "Epoch 58/60\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9932 - val_loss: 1.0387 - val_accuracy: 0.8699\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9795 - val_loss: 0.8815 - val_accuracy: 0.8630\n",
      "Epoch 60/60\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9807 - val_loss: 0.9419 - val_accuracy: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe0f2ae5790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=10, epochs=60,validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "eCEiuWjBDFTz",
    "outputId": "6ffca04d-d9e6-459b-dedb-8b12049ccbe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.66%\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 8,0,2,0,0,0,0,2\n",
      "Clapping , 0,12,0,0,0,0,0,0\n",
      "Falling , 0,0,8,0,0,0,0,4\n",
      "Sweeping , 0,0,0,6,0,0,0,0\n",
      "WashingHand , 0,0,0,0,5,0,0,1\n",
      "WatchingTV , 0,0,0,0,0,6,0,0\n",
      "enteringExiting , 0,0,0,0,0,0,14,0\n",
      "other , 0,0,0,1,2,4,0,143\n",
      "\n",
      "activity,Calling,Clapping,Falling,Sweeping,WashingHand,WatchingTV,enteringExiting,other\n",
      "Calling , 0.67,0.0,0.17,0.0,0.0,0.0,0.0,0.17\n",
      "Clapping , 0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "Falling , 0.0,0.0,0.67,0.0,0.0,0.0,0.0,0.33\n",
      "Sweeping , 0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0\n",
      "WashingHand , 0.0,0.0,0.0,0.0,0.83,0.0,0.0,0.17\n",
      "WatchingTV , 0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0\n",
      "enteringExiting , 0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0\n",
      "other , 0.0,0.0,0.0,0.01,0.01,0.03,0.0,0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(Y_test)):\n",
    "    if(np.amax(result[i])<0.5):\n",
    "#       pred = 11\n",
    "      pred = np.argmax(result[i])\n",
    "    else:\n",
    "      pred = np.argmax(result[i])\n",
    "    if np.argmax(y_test[i])==pred:\n",
    "        cnt+=1\n",
    "\n",
    "acc = str(round(cnt*100/float(len(Y_test)),2))\n",
    "print(\"Accuracy: \" + acc + \"%\")\n",
    "\n",
    "showResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"Models/audio_NN_New\"\n",
    "try:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "except OSError:\n",
    "    print(\"Error: Creating Directory: \" + dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfVN64yTDIhq"
   },
   "outputs": [],
   "source": [
    "## save model (optional)\n",
    "\n",
    "path = dir_path+datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "model_json = model.to_json()\n",
    "with open(path+\"_acc_\"+acc+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(path+\"_acc_\"+acc+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qft5RNixHVHc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "activityReduced_NN_STFT_mean.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
