{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_ing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBnJZ/uaUhsM3tUBwiPa0K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brillantescene/Capstone_Design/blob/master/cnn_ing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3gGvshmtgvH",
        "colab_type": "text"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v72-5GbJthzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqihsPL5aceV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2cVUHtnIR8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fd8fff9-291c-483e-c713-264c93c2f8a4"
      },
      "source": [
        "from tensorflow import keras #import keras\n",
        "from tensorflow.keras import Model\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3lvAw2x_Vf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sFsbh-saeHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZyoTkre7Rjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PXMeVHKtJ_3",
        "colab_type": "text"
      },
      "source": [
        "## Retrieve the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nem5TSq7UpKm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5b0c44a0-766b-4070-f83e-1f38d21d6cd9"
      },
      "source": [
        "data_dir = tf.keras.utils.get_file(origin='https://github.com/CapstoneDesign2020/machineLearning/raw/master/dataPreprocessing/test_img.tgz', \n",
        "                                   fname='acoustic_images', extract=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/CapstoneDesign2020/machineLearning/raw/master/dataPreprocessing/test_img.tgz\n",
            "78209024/78202245 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KHpiahFeCt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = pathlib.PosixPath(\"/root/.keras/datasets/test_img\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnLszM4OUpWx",
        "colab_type": "code",
        "outputId": "994c0b18-f8b7-4a51-fc02-083601e6bfb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data_dir)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets/test_img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb-0E4I_U2tr",
        "colab_type": "code",
        "outputId": "4b204fa7-9baa-42ef-b8de-b586c330b4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_count = len(list(data_dir.glob('*/*.png')))\n",
        "image_count"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3440"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBe2LmjWA2-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0c1c6be-ce7d-4558-fe6a-0920006aa49b"
      },
      "source": [
        "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*')])\n",
        "CLASS_NAMES"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['motor', 'drop', 'water'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnDKKziGu7is",
        "colab_type": "text"
      },
      "source": [
        "## Load using tf.data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqHUnO7SA3D2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sweMPoW8A3G9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "09428d19-bd65-4d93-8691-35449051cc33"
      },
      "source": [
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'/root/.keras/datasets/test_img/motor/0-833.png'\n",
            "b'/root/.keras/datasets/test_img/drop/1-253.png'\n",
            "b'/root/.keras/datasets/test_img/motor/0-438.png'\n",
            "b'/root/.keras/datasets/test_img/water/1-1189.png'\n",
            "b'/root/.keras/datasets/test_img/water/1-1178.png'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-466UMvqjZy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "training_epochs = 100\n",
        "BATCH_SIZE = 32\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaGDtC97vYYq",
        "colab_type": "text"
      },
      "source": [
        "파일 경로를 `(img, label)`쌍으로 변환하는 짧은 순수 tensorflow 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toY5Dc4jA3NG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        "  #path를 path 구성 요소 목록으로 변환\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # 마지막 두 번째가 클래스 디렉터리임\n",
        "  return parts[-2] == CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsRR3llDA3QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_img(img):\n",
        "  # 압축된 문자열을 3D uint8 텐서로 변환\n",
        "  img = tf.image.decode_png(img, channels=3)\n",
        "  # convert_image_dtype로 [0,1] 범위의 float로 변환\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # 이미지 크기를 원하는 크기로 조정\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6-d5_XA3LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # 파일에서 raw data를 문자열로 로드\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PhQBMVGi7yx",
        "colab_type": "text"
      },
      "source": [
        "`image, label` 쌍 데이터셋 만들기 위해 `Dataset.map`사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0S5tVpi6sU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지가 병렬로 로드/처리되도록 'num_parallel_calls'를 설정한다.\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2J0bVu69-wA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c7dd8f71-c1c9-46bc-c57b-8cf1515e4792"
      },
      "source": [
        "print(type(labeled_ds))\n",
        "print(labeled_ds)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'>\n",
            "<ParallelMapDataset shapes: ((224, 224, 3), (3,)), types: (tf.float32, tf.bool)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9USZoENjjey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "065884a7-fcc5-41e4-ec23-a65f6485292a"
      },
      "source": [
        "for image, label in labeled_ds.take(1):\n",
        "  print(\"Image shape: \", image.numpy().shape)\n",
        "  print(\"Label: \", label.numpy())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image shape:  (224, 224, 3)\n",
            "Label:  [False False  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwcws5Q0-dt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # 이것은 작은 데이터 집합으로, 한 번만 로드하여 메모리에 보관한다.\n",
        "  # 데이터셋의 사전 처리 작업을 캐싱하기 위해 '.cache(filename)' 사용\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  ds = ds.repeat()\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVkKCv_X-h0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = prepare_for_training(labeled_ds)\n",
        "image_batch, label_batch = next(iter(train_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDlsBIEx4wkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = prepare_for_training(labeled_ds)\n",
        "image_batch, label_batch = next(iter(dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp1k6_bJ9PUX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "80ad9d3b-0f0c-40e5-d79f-44100e52a5cc"
      },
      "source": [
        "for image_batch, labels_batch in dataset:\n",
        "  print('batch data size:', image_batch.shape)\n",
        "  print('batch label size:', labels_batch.shape)\n",
        "  break  "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch data size: (32, 224, 224, 3)\n",
            "batch label size: (32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWP58Jcw44Wn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "6cb64841-ed1c-4b71-f318-8ce0007b0a51"
      },
      "source": [
        "(train_x, train_y), (test_x, test_y) = "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-00160686284a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_ds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNJk3v7b-rbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def show_batch(image_batch, label_batch):\n",
        "#  plt.figure(figsize=(10,10))\n",
        "#  for n in range(25):\n",
        "#      ax = plt.subplot(5,5,n+1)\n",
        "#      plt.imshow(image_batch[n])\n",
        "#      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "#      plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfUS9Dou-kfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEXB6uQr_o3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#val_ds = prepare_for_training(labeled_ds)\n",
        "#val_image_batch, val_label_batch = next(iter(val_ds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZSeLFEo82RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#show_batch(test_image_batch.numpy(), test_label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_PhDBif3wZ9",
        "colab_type": "text"
      },
      "source": [
        "## 모델 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7y3R3WguycR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AcousticSoundModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(AcousticSoundModel, self).__init__()\n",
        "        self.conv1 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop1 = Dropout(rate=0.2)\n",
        "        self.pool1 = MaxPool2D(padding='SAME') ###### pooling 2x2. stride는 표기 x, 확인 ######\n",
        "        \n",
        "        self.conv2 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop2 = Dropout(rate=0.2) #20% dropout\n",
        "        self.pool2 = MaxPool2D(padding='SAME')\n",
        "        \n",
        "        self.conv3 = Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n",
        "        self.drop3 = Dropout(rate=0.2) #20% dropout\n",
        "        self.pool3 = MaxPool2D(padding='SAME')\n",
        "        \n",
        "        self.pool3_flat = keras.layers.Flatten()\n",
        "        self.dense4 = Dense(units=128, activation=tf.nn.relu)\n",
        "        self.dense5 = Dense(units=5, activation=tf.nn.sigmoid) ### 일단 5. class 개수 추가되는 대로 변경\n",
        "        \n",
        "    def call(self, inputs, training=False):\n",
        "        net = self.conv1(inputs)\n",
        "        net = self.drop1(net)\n",
        "        net = self.pool1(net)\n",
        "        \n",
        "        net = self.conv2(net)\n",
        "        net = self.drop2(net)\n",
        "        net = self.pool2(net)\n",
        "        \n",
        "        net = self.conv3(net)\n",
        "        net = self.drop3(net)\n",
        "        net = self.pool3(net)\n",
        "        \n",
        "        net = self.pool3_flat(net)\n",
        "        net = self.dense4(net)\n",
        "        net = self.dense5(net)\n",
        "        return net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyyCrX1wH_Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = AcousticSoundModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBDRzz_M315_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPOJcmo9AYZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpwE1c7b_noF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sItLd2TjADMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-80fTlyuAYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 저장된 모델을 언제든지 로드하고 평가할 수 있습니다.\n",
        "saved_model = load_model('best_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC82XvTesL5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cb_list = [early_stopping, save]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujEWoqNnFDDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "a44c3df2-517b-4158-f9d5-2bf6802846a6"
      },
      "source": [
        "hist = model.fit(\n",
        "      train_ds,\n",
        "      steps_per_epoch=25, # batch크기 4, 전체 200개 샘플이니까 25\n",
        "      epochs=training_epochs,\n",
        "      batch_size = BATCH_SIZE,\n",
        "      validation_data=val_ds)\n",
        "      #validation_steps=12)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-43ed17c4188d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       callbacks=cb_list)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             steps=data_handler.inferred_steps)\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, callbacks, add_history, add_progbar, model, **params)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     self._should_call_train_batch_hooks = any(\n\u001b[0;32m--> 231\u001b[0;31m         cb._implements_train_batch_hooks() for cb in self.callbacks)\n\u001b[0m\u001b[1;32m    232\u001b[0m     self._should_call_test_batch_hooks = any(\n\u001b[1;32m    233\u001b[0m         cb._implements_test_batch_hooks() for cb in self.callbacks)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EarlyStopping' object has no attribute '_implements_train_batch_hooks'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA7H_I-rFDHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('images_small_2', save_format='tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dZByyRV_htE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ume5AnKPAYSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#history = model.fit_generator(\n",
        "#      train_generator,\n",
        "#      steps_per_epoch=25, # batch크기 4, 전체 200개 샘플이니까 25\n",
        "#      epochs=training_epochs,\n",
        "#      validation_data=validation_generator,\n",
        "#      validation_steps=12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arih6Uuo6mWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explore your VM\n",
        "#!ls -la /\n",
        "# Find disk space and RAM space\n",
        "#!df -h\n",
        "#!free -m\n",
        "\n",
        "#What OS is your VM using:\n",
        "#!cat /etc/os-release"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVmPr9dBYX-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls  /root/.keras/datasets/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8vhH9U0YaNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!ls  /root/.keras/datasets/images.tar.gz/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}