{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import genfromtxt\n",
    "import gzip\n",
    "import _pickle\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "[[[ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  ...\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]]\n",
      "\n",
      " [[ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  ...\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]]\n",
      "\n",
      " [[ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  ...\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]\n",
      "  [ 0  0  4]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 3  0 11]\n",
      "  [17  4 32]\n",
      "  [45 13 45]\n",
      "  ...\n",
      "  [25  8 30]\n",
      "  [27  9 30]\n",
      "  [12  4 18]]\n",
      "\n",
      " [[83 35 64]\n",
      "  [92 43 62]\n",
      "  [69 30 51]\n",
      "  ...\n",
      "  [15  5 25]\n",
      "  [37 13 35]\n",
      "  [30 10 31]]\n",
      "\n",
      " [[30 15 20]\n",
      "  [34 20 21]\n",
      "  [32 16 21]\n",
      "  ...\n",
      "  [ 6  2 14]\n",
      "  [12  4 16]\n",
      "  [10  3 14]]]\n"
     ]
    }
   ],
   "source": [
    "img=imageio.imread(\"train/drop-0.png\", pilmode='RGB')\n",
    "print(img.shape)\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2760,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", names = [\"class\"])\n",
    "np.array(df[\"class\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gonna process:\n",
      "\t train/*.png\n",
      "\t 0 files processed\n",
      "\t 1000 files processed\n",
      "\t 2000 files processed\n",
      "Gonna process:\n",
      "\t valid/*.png\n",
      "\t 0 files processed\n",
      "Gonna process:\n",
      "\t test/*.png\n",
      "\t 0 files processed\n"
     ]
    }
   ],
   "source": [
    "def dir_to_dataset(glob_files, loc_train_labels=\"\"):\n",
    "    print(\"Gonna process:\\n\\t %s\"%glob_files)\n",
    "    dataset = []\n",
    "    for file_count, file_name in enumerate( sorted(glob(glob_files),key=len) ):\n",
    "        img=imageio.imread(file_name, pilmode='RGB')\n",
    "        #print(img.shape)\n",
    "        #pixels = [f[0] for f in list(img.getdata())]\n",
    "        dataset.append(img)\n",
    "        if file_count % 1000 == 0:\n",
    "            print(\"\\t %s files processed\"%file_count)\n",
    "    # outfile = glob_files+\"out\"\n",
    "    # np.save(outfile, dataset)\n",
    "    if len(loc_train_labels) > 0:\n",
    "        df = pd.read_csv(loc_train_labels, names = [\"class\"])\n",
    "        return np.array(dataset), np.array(df[\"class\"])\n",
    "    else:\n",
    "        return np.array(dataset)\n",
    "    \n",
    "Data1, y1 = dir_to_dataset(\"train/*.png\",\"train.csv\")\n",
    "Data2, y2 = dir_to_dataset(\"valid/*.png\",\"valid.csv\")\n",
    "Data3, y3 = dir_to_dataset(\"test/*.png\",\"test.csv\")\n",
    "\n",
    "# Data and labels are read \n",
    "train_num = 2758\n",
    "valid_num = 844\n",
    "test_num = 420\n",
    "\n",
    "train_set_x = Data1[:train_num]\n",
    "train_set_y = y1[1:train_num+1]\n",
    "val_set_x = Data2[:valid_num]\n",
    "val_set_y = y2[1:valid_num+1]\n",
    "test_set_x = Data3[:test_num]\n",
    "test_set_y = y3[1:test_num+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided dataset into 3 parts. I had 7717 images for training, 1653 images for validation and 1654 images for testing\n",
    "\n",
    "train_set = train_set_x, train_set_y\n",
    "val_set = val_set_x, val_set_y\n",
    "test_set = test_set_x, test_set_y\n",
    "\n",
    "dataset = [train_set, val_set, test_set]\n",
    "\n",
    "f = gzip.open('soundee.pkl.gz','wb')\n",
    "_pickle.dump(dataset, f, protocol=2)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
